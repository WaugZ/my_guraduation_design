论文主体的内容根据不同学科有不同的特点，一般应包括以下几个方面：
（1）毕业论文（设计）总体方案或选题的论证；
（2）毕业论文（设计）各部分的设计实现，包括实验数据的获取、数据可行性及有效性的处理与分析、各部分的设计计算等；
（3）对研究内容及成果的客观阐述，包括理论依据、创新见解、创造性成果及其改进与实际应用价值等；
（4）论文主体的所有数据必须真实可靠，凡引用他人观点、方案、资料、数据等，无论曾否发表，无论是纸质或电子版，均应详加注释。自然科学论文应推理正确、结论清晰；人文和社会学科的论文应把握论点正确、论证充分、论据可靠，恰当运用系统分析和比较研究的方法进行模型或方案设计，注重实证研究和案例分析，根据分析结果提出建议和改进措施等。

Reference(or may be refered)
https://en.wikipedia.org/wiki/Convolutional_neural_network
http://ieeexplore.ieee.org/document/726791/?reload=true&arnumber=726791

# 第一章 简介（背景）

我的设计一键建模系统(One Button Modeling System)应用了当下图像处理中较流行的卷积神经网络，使用了爬虫技术作为数据获取的手段，Flask和Jina2框架作为数据展示的平台，它的功能是用户在网页输入一个（一组）关键词，服务器将根据此关键词从京东(www.jd.com)中抓取数据，然后经过聚类，进行自动化的数据清理，利用清理后的数据进行建模；建模完成后，用户可以输入一张图片，服务器将把这张图片经过模型，用置信度的方式告诉用户这张图片与其建模对象是否一致。

最近深度学习技术常常被主流媒体曝光，其智能让许多人惊艳，但苦于技术、算力和数据的门槛，一般人很难近距离的接触这项技术，只能远观，等待着技术成熟，自己能够体验到这项技术。而这个系统可以让对深度学习技术知之甚少甚至完全不了解的人也能够简单地、只需按下一个按钮地创建属于自己的模型，感受深度学习技术的魅力与其强大的图像识别能力。

## 1.1 卷积神经网络

### 1.1.1 卷积神经网络综述

卷积神经网络(convolutional neural network, CNN)是机器学习中一种深层的、人工构造的前馈神经网络，在计算机视觉领域有着出色的效果。卷积神经网络使用多层感知器（multilayer perceptron, MLP）的变体来作为数据预处理，这种处理的特征是空间不变性，因为网络中层与层之间的参数是共享的。
卷积神经网络期初启发于一个生物实验：该实验发现被实验的哺乳动物仅在视野中有明显的边界变化时，最初的视觉神经元会有激活反应，这与图像处理中的卷积类似，同样适用于处理边界信息，卷积神经网络便在这一启发下应运而生。
CNN较于传统的神经网络更适合于处理图像，因为它需要的预处理要少得多，它几乎是端对端的，即输入是原始图片输出是网络的预测结果，网络将自动学习到许多用于识别图像的特征，而传统的方法则需要人工构造这些特征，它不需要人工的先验知识并尽可能避免人为构造特征可能对后续设计的影响，这是CNN作为机器学习方法之一的一大优势。

CNN包括一个输入层、一个输出层和若干隐藏层，隐藏层一般由三种结构组成，它们分别为卷积层(Convolutional layer, conv)、池化层(Pooling layer, pool)、全连接层(Full connected, FC)

在卷积层中，对输入数据进行卷积操作（在数学领域中，应当称为“相关(cross-correlation)”），将输出经过一个激活函数（包括经典的曲线激活函数(Sigmoid)，在深度网络中更有实践意义的tanh函数和ReLu函数）后传入下一层中。每个卷积层神经元仅在相关的区域进行数据操作，也即局部性。传统的全连接前馈神经网络不是一个适合处理图像数据的结构，若要这么做，则需要大量的神经元作为图像的像素点作为输入，而全连接这些神经元则需要大量的参数，例如一张100*100*3的图片作为输入，第二层为96*96*3，全连接这2层神经元需要829470000((96^2*3+1) * (100^2 * 3))个参数，这样不必说深层神经网络结构，就算是浅层结构也需要大量的参数和大量的算力，更重要的是在反向传播中会出现梯度消失或梯度爆炸的情况，导致网络无法训练。而使用具有局部特性的卷积层，则只需要78(（5*5+1）*3 )个参数即可完成两个神经网路层间的数据传递，同时数据处理的局部性更贴近于生物的视觉——接近的像素点更可能有某种联系。

池化层常出现在CNN中，它将多个神经元的输出到单一个神经元中，起到一种类似于压缩的作用。常用最大池化层，即将输入的多个神经元取激活值最大的那个作为输出。池化层的主要作用是压缩数据，加快训练网络的速度，但同时压缩导致的数据失真也被其他一些图像处理的方法所诟病。

全连接层与传统多层感知器（multilayer perceptron, MLP）中层与层之间神经元的联系大体相同。在CNN中，输入从一般先通过若干卷积层和池化层，得到网络自动提取的图像特征值——一个向量，然后经过若干个全连接层，最后连接到输出层，对应不同的任务有多种输出层，如处理多分类的softmax loss，处理实数标签的Euclidean loss等。

### 1.1.2 检测网络

### 1.1.3 识别网络

## 1.2 爬虫技术

## 1.3 flask与jina2

# 第二章 相关研究

# 第三章 实验过程

# 第四章 结论